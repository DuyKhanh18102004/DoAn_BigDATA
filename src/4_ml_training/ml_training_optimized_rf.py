#!/usr/bin/env python3
"""
ML Training - OPTIMIZED Random Forest with Enhanced Hyperparameters
Train on 5 MIXED batches with powerful RF configuration
- Fixed: Sá»­ dá»¥ng image_id thá»±c thay vÃ¬ monotonically_increasing_id()
- Fixed: LÆ°u probability vectors cho ensemble chÃ­nh xÃ¡c
- Optimized: Chá»‰ training trÃªn táº­p train, khÃ´ng dÃ¹ng test data
- Optimized: Clean code patterns cho BigData processing
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col, lit, avg as spark_avg, when,
    hash as spark_hash, concat_ws, udf
)
from pyspark.sql.types import DoubleType, StringType
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.functions import vector_to_array
import time
import gc

print("="*80)
print("ğŸŒ² ML TRAINING - OPTIMIZED RANDOM FOREST")
print("="*80)

# Initialize Spark with optimized config
spark = SparkSession.builder \
    .appName("ML_Training_Optimized_RF") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .config("spark.executor.cores", "2") \
    .config("spark.default.parallelism", "50") \
    .config("spark.sql.shuffle.partitions", "50") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()

# Set log level Ä‘á»ƒ giáº£m noise
spark.sparkContext.setLogLevel("WARN")

pipeline_start = time.time()

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def create_image_id(df, source_type):
    """
    Táº¡o image_id duy nháº¥t tá»« features hash + source info.
    Äáº£m báº£o ID nháº¥t quÃ¡n khi join giá»¯a cÃ¡c model predictions.
    """
    # Táº¡o hash tá»« features vector Ä‘á»ƒ cÃ³ ID duy nháº¥t cho má»—i áº£nh
    # Káº¿t há»£p vá»›i source_type Ä‘á»ƒ trÃ¡nh collision giá»¯a REAL/FAKE
    return df.withColumn(
        "image_id",
        concat_ws("_", 
            lit(source_type),
            spark_hash(col("features").cast("string"))
        ).cast(StringType())
    )

def get_probability_at_index(prob_col, index):
    """Extract probability at specific index from probability vector."""
    return vector_to_array(prob_col)[index]

# ============================================================================
# CONFIGURATION
# ============================================================================

HDFS_BASE = "hdfs://namenode:8020/user/data"
NUM_BATCHES = 5
VALIDATION_RATIO = 0.2  # 20% cho validation tá»« train data
SEED = 42

# Hyperparameters tá»‘i Æ°u
RF_PARAMS = {
    "numTrees": 100,
    "maxDepth": 15,
    "minInstancesPerNode": 1,
    "featureSubsetStrategy": "sqrt",
    "seed": SEED
}

# ============================================================================
# STEP 1: Load vÃ  Prepare Training Data tá»« 5 Batches
# ============================================================================

print("\n" + "="*80)
print("ğŸ“‚ STEP 1: Loading Training Data (5 Mixed Batches)")
print("="*80)

all_train_data = []
total_train_samples = 0

for batch_id in range(1, NUM_BATCHES + 1):
    print(f"\nğŸ“¦ Loading Batch {batch_id}/{NUM_BATCHES}...")
    
    # Load REAL
    real_path = f"{HDFS_BASE}/features/train/REAL/batch_{batch_id}"
    df_real = spark.read.parquet(real_path)
    df_real = create_image_id(df_real, f"REAL_batch{batch_id}")
    real_count = df_real.count()
    
    # Load FAKE  
    fake_path = f"{HDFS_BASE}/features/train/FAKE/batch_{batch_id}"
    df_fake = spark.read.parquet(fake_path)
    df_fake = create_image_id(df_fake, f"FAKE_batch{batch_id}")
    fake_count = df_fake.count()
    
    # Union vÃ  thÃªm batch_id
    df_batch = df_real.union(df_fake).withColumn("batch_id", lit(batch_id))
    all_train_data.append(df_batch)
    
    batch_count = real_count + fake_count
    total_train_samples += batch_count
    print(f"   âœ… REAL: {real_count:,} | FAKE: {fake_count:,} | Total: {batch_count:,}")

# Union táº¥t cáº£ batches
print(f"\nğŸ”— Combining all {NUM_BATCHES} batches...")
df_train_full = all_train_data[0]
for df in all_train_data[1:]:
    df_train_full = df_train_full.union(df)

# Repartition Ä‘á»ƒ tá»‘i Æ°u xá»­ lÃ½
df_train_full = df_train_full.repartition(50, "image_id").cache()
actual_count = df_train_full.count()

print(f"âœ… Total training data: {actual_count:,} samples")
print(f"   - Expected: {total_train_samples:,}")

# ============================================================================
# STEP 2: Split Train/Validation (80/20)
# ============================================================================

print("\n" + "="*80)
print("ğŸ“Š STEP 2: Creating Train/Validation Split")
print("="*80)

# Split vá»›i stratified sampling Ä‘á»ƒ giá»¯ balance giá»¯a classes
df_train, df_val = df_train_full.randomSplit([1-VALIDATION_RATIO, VALIDATION_RATIO], seed=SEED)
df_train = df_train.cache()
df_val = df_val.cache()

train_count = df_train.count()
val_count = df_val.count()

# Kiá»ƒm tra class distribution
train_label_dist = df_train.groupBy("label").count().collect()
val_label_dist = df_val.groupBy("label").count().collect()

print(f"âœ… Training set: {train_count:,} samples")
for row in train_label_dist:
    label_name = "REAL" if row["label"] == 1 else "FAKE"
    print(f"   - {label_name} (label={row['label']}): {row['count']:,}")

print(f"\nâœ… Validation set: {val_count:,} samples")
for row in val_label_dist:
    label_name = "REAL" if row["label"] == 1 else "FAKE"
    print(f"   - {label_name} (label={row['label']}): {row['count']:,}")

# Unpersist full data Ä‘á»ƒ giáº£i phÃ³ng memory
df_train_full.unpersist()

# ============================================================================
# STEP 3: Train Random Forest Models vá»›i Cross-Validation trÃªn Batches
# ============================================================================

print("\n" + "="*80)
print("ğŸŒ² STEP 3: Training Random Forest Models")
print("="*80)
print("\nğŸ”§ HYPERPARAMETERS:")
for key, value in RF_PARAMS.items():
    print(f"   - {key}: {value}")

# Láº¥y unique batches Ä‘á»ƒ train riÃªng biá»‡t (ensemble approach)
batch_ids = [row["batch_id"] for row in df_train.select("batch_id").distinct().collect()]
batch_ids.sort()

print(f"\nğŸ“¦ Training {len(batch_ids)} models (one per batch)...")

model_predictions = []
individual_accuracies = []

for batch_id in batch_ids:
    print(f"\n{'='*80}")
    print(f"ğŸ“¦ Model {batch_id}/{len(batch_ids)}: Training on Batch {batch_id}")
    print(f"{'='*80}")
    
    batch_start = time.time()
    
    # Filter data cho batch nÃ y
    df_batch_train = df_train.filter(col("batch_id") == batch_id).cache()
    batch_count = df_batch_train.count()
    print(f"   ğŸ“Š Training samples: {batch_count:,}")
    
    # Train Random Forest
    print("   ğŸŒ² Training Random Forest...")
    rf = RandomForestClassifier(
        featuresCol="features",
        labelCol="label",
        **RF_PARAMS
    )
    
    rf_model = rf.fit(df_batch_train)
    print("   âœ… Training completed!")
    
    # Predict trÃªn VALIDATION set (khÃ´ng pháº£i test!)
    print("   ğŸ”® Predicting on validation set...")
    predictions = rf_model.transform(df_val)
    
    # LÆ°u predictions vá»›i image_id thá»±c (QUAN TRá»ŒNG: khÃ´ng dÃ¹ng monotonically_increasing_id)
    # Extract probability cho class 1 (REAL) Ä‘á»ƒ ensemble averaging
    predictions = predictions.select(
        col("image_id"),
        col("label"),
        col("prediction").alias(f"pred_{batch_id}"),
        vector_to_array(col("probability"))[1].alias(f"prob_{batch_id}")
    )
    
    # Cache Ä‘á»ƒ dÃ¹ng cho ensemble
    predictions = predictions.cache()
    pred_count = predictions.count()
    
    # Evaluate single model accuracy
    correct = predictions.filter(col("label") == col(f"pred_{batch_id}")).count()
    single_acc = correct / pred_count
    individual_accuracies.append(single_acc)
    print(f"   ğŸ“Š Single model accuracy: {single_acc*100:.2f}%")
    
    # LÆ°u predictions vÃ o HDFS
    pred_path = f"{HDFS_BASE}/predictions/rf_model_{batch_id}"
    print(f"   ğŸ’¾ Saving predictions to: {pred_path}")
    predictions.write.mode("overwrite").parquet(pred_path)
    
    model_predictions.append({
        'batch_id': batch_id,
        'pred_path': pred_path,
        'accuracy': single_acc
    })
    
    batch_elapsed = time.time() - batch_start
    print(f"   âœ… Model {batch_id} completed in {batch_elapsed:.2f}s")
    
    # Memory cleanup
    df_batch_train.unpersist()
    predictions.unpersist()
    del rf_model
    spark.catalog.clearCache()
    gc.collect()
    time.sleep(2)

print("\n" + "="*80)
print(f"âœ… All {len(batch_ids)} Random Forest models trained!")
print("="*80)

# Show individual accuracies
print("\nğŸ“Š Individual Model Accuracies:")
avg_individual = sum(individual_accuracies) / len(individual_accuracies)
for mp in model_predictions:
    print(f"   Model {mp['batch_id']}: {mp['accuracy']*100:.2f}%")
print(f"\n   ğŸ“ˆ Average: {avg_individual*100:.2f}%")

# ============================================================================
# STEP 4: Ensemble Predictions - Probability Averaging (ChÃ­nh xÃ¡c hÆ¡n Majority Voting)
# ============================================================================

print("\n" + "="*80)
print("ğŸ”® STEP 4: Ensemble Predictions (Probability Averaging)")
print("="*80)

# Load vÃ  join predictions sá»­ dá»¥ng image_id thá»±c (FIX cho bug monotonically_increasing_id)
print("ğŸ“‚ Loading prediction batch 1 as base...")
df_ensemble = spark.read.parquet(model_predictions[0]['pred_path'])
print(f"   âœ… Base loaded: {df_ensemble.count():,} rows")

# Join incrementally vá»›i cÃ¡c predictions cÃ²n láº¡i
for mp in model_predictions[1:]:
    batch_id = mp['batch_id']
    print(f"\nğŸ“‚ Loading and joining prediction batch {batch_id}...")
    
    df_pred = spark.read.parquet(mp['pred_path'])
    
    # Join báº±ng image_id (CHÃNH XÃC - khÃ´ng bá»‹ láº«n lá»™n giá»¯a cÃ¡c áº£nh)
    df_ensemble = df_ensemble.join(
        df_pred.select("image_id", f"pred_{batch_id}", f"prob_{batch_id}"),
        on="image_id",
        how="inner"
    )
    
    count = df_ensemble.count()
    print(f"   âœ… Joined: {count:,} rows")

df_ensemble = df_ensemble.repartition(20).cache()
ensemble_count = df_ensemble.count()

print(f"\nâœ… Ensemble data ready: {ensemble_count:,} samples")

# ============================================================================
# STEP 5: Calculate Ensemble Prediction vá»›i Probability Averaging
# ============================================================================

print("\n" + "="*80)
print("ğŸ¯ STEP 5: Calculating Ensemble Prediction")
print("="*80)

# TÃ­nh trung bÃ¬nh probability tá»« táº¥t cáº£ models
# ÄÃ¢y lÃ  cÃ¡ch ensemble chÃ­nh xÃ¡c hÆ¡n majority voting
prob_cols = [f"prob_{mp['batch_id']}" for mp in model_predictions]
print(f"ğŸ“Š Averaging probabilities from {len(prob_cols)} models...")

# TÃ­nh average probability cho class REAL (label=1)
avg_prob_expr = sum([col(c) for c in prob_cols]) / len(prob_cols)

df_ensemble = df_ensemble.withColumn("avg_probability", avg_prob_expr)

# Predict: náº¿u avg_prob >= 0.5 thÃ¬ predict REAL (1), ngÆ°á»£c láº¡i FAKE (0)
df_ensemble = df_ensemble.withColumn(
    "ensemble_prediction",
    when(col("avg_probability") >= 0.5, 1.0).otherwise(0.0)
)

df_ensemble = df_ensemble.cache()

print("âœ… Ensemble predictions calculated!")

# Show sample
print("\nğŸ“Š Sample predictions:")
sample_cols = ["image_id", "label"] + prob_cols[:3] + ["avg_probability", "ensemble_prediction"]
df_ensemble.select(*sample_cols).show(5, truncate=False)

# ============================================================================
# STEP 6: Evaluate Ensemble Performance trÃªn Validation Set
# ============================================================================

print("\n" + "="*80)
print("ğŸ“Š STEP 6: Evaluating Ensemble Performance (Validation Set)")
print("="*80)

# Accuracy
evaluator_acc = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="ensemble_prediction",
    metricName="accuracy"
)
ensemble_acc = evaluator_acc.evaluate(df_ensemble)

# Precision
evaluator_prec = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="ensemble_prediction",
    metricName="weightedPrecision"
)
ensemble_prec = evaluator_prec.evaluate(df_ensemble)

# Recall
evaluator_rec = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="ensemble_prediction",
    metricName="weightedRecall"
)
ensemble_rec = evaluator_rec.evaluate(df_ensemble)

# F1-Score
evaluator_f1 = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="ensemble_prediction",
    metricName="f1"
)
ensemble_f1 = evaluator_f1.evaluate(df_ensemble)

# TÃ­nh Confusion Matrix metrics thá»§ cÃ´ng
tp = df_ensemble.filter((col("label") == 1) & (col("ensemble_prediction") == 1)).count()
tn = df_ensemble.filter((col("label") == 0) & (col("ensemble_prediction") == 0)).count()
fp = df_ensemble.filter((col("label") == 0) & (col("ensemble_prediction") == 1)).count()
fn = df_ensemble.filter((col("label") == 1) & (col("ensemble_prediction") == 0)).count()

print("\nğŸ“Š Confusion Matrix:")
print(f"   TP (REAL predicted as REAL): {tp:,}")
print(f"   TN (FAKE predicted as FAKE): {tn:,}")
print(f"   FP (FAKE predicted as REAL): {fp:,}")
print(f"   FN (REAL predicted as FAKE): {fn:,}")

# ============================================================================
# STEP 7: Save Training Results to HDFS
# ============================================================================

print("\n" + "="*80)
print("ğŸ’¾ STEP 7: Saving Training Results to HDFS")
print("="*80)

# Save validation predictions (vá»›i probability Ä‘á»ƒ evaluation step cÃ³ thá»ƒ tÃ­nh AUC Ä‘Ãºng)
val_predictions_path = f"{HDFS_BASE}/results/validation_predictions"
print(f"\nğŸ“Š Saving validation predictions to: {val_predictions_path}")
df_ensemble.select(
    "image_id", "label", "ensemble_prediction", "avg_probability"
).write.mode("overwrite").parquet(val_predictions_path)
print("âœ… Validation predictions saved!")

# Save detailed predictions vá»›i táº¥t cáº£ model votes
detailed_path = f"{HDFS_BASE}/results/validation_detailed"
print(f"\nğŸ“Š Saving detailed predictions to: {detailed_path}")
df_ensemble.write.mode("overwrite").parquet(detailed_path)
print("âœ… Detailed predictions saved!")

# Save training metrics
from pyspark.sql import Row
metrics_data = [
    Row(metric="Accuracy", value=float(ensemble_acc)),
    Row(metric="Precision", value=float(ensemble_prec)),
    Row(metric="Recall", value=float(ensemble_rec)),
    Row(metric="F1_Score", value=float(ensemble_f1)),
    Row(metric="Validation_Samples", value=float(ensemble_count)),
    Row(metric="Training_Samples", value=float(train_count)),
    Row(metric="Num_Models", value=float(len(model_predictions))),
    Row(metric="NumTrees", value=float(RF_PARAMS["numTrees"])),
    Row(metric="MaxDepth", value=float(RF_PARAMS["maxDepth"])),
    Row(metric="TP", value=float(tp)),
    Row(metric="TN", value=float(tn)),
    Row(metric="FP", value=float(fp)),
    Row(metric="FN", value=float(fn)),
    Row(metric="Avg_Individual_Accuracy", value=float(avg_individual))
]
df_metrics = spark.createDataFrame(metrics_data)
metrics_path = f"{HDFS_BASE}/results/training_metrics"
print(f"\nğŸ“Š Saving training metrics to: {metrics_path}")
df_metrics.write.mode("overwrite").parquet(metrics_path)
print("âœ… Training metrics saved!")

# Save model info cho evaluation step
model_info_path = f"{HDFS_BASE}/results/model_info"
model_info_data = [
    Row(
        batch_id=mp['batch_id'],
        pred_path=mp['pred_path'],
        accuracy=float(mp['accuracy'])
    ) for mp in model_predictions
]
df_model_info = spark.createDataFrame(model_info_data)
print(f"\nğŸ“Š Saving model info to: {model_info_path}")
df_model_info.write.mode("overwrite").parquet(model_info_path)
print("âœ… Model info saved!")

print("\n" + "="*80)
print("âœ… All training results saved to HDFS!")
print("="*80)
print(f"   - Validation predictions: {val_predictions_path}")
print(f"   - Detailed predictions: {detailed_path}")
print(f"   - Training metrics: {metrics_path}")
print(f"   - Model info: {model_info_path}")

print("\n" + "="*80)
print("ğŸŒ² RANDOM FOREST ENSEMBLE - TRAINING RESULTS")
print("="*80)
print(f"ğŸ“Š Training samples: {train_count:,}")
print(f"ğŸ“Š Validation samples: {ensemble_count:,}")
print(f"\nğŸ¯ Validation Metrics:")
print(f"   Accuracy:  {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)")
print(f"   Precision: {ensemble_prec:.4f} ({ensemble_prec*100:.2f}%)")
print(f"   Recall:    {ensemble_rec:.4f} ({ensemble_rec*100:.2f}%)")
print(f"   F1-Score:  {ensemble_f1:.4f} ({ensemble_f1*100:.2f}%)")

print(f"\nğŸ“ˆ Ensemble Improvement:")
print(f"   Average Individual Model: {avg_individual*100:.2f}%")
print(f"   Ensemble (Prob Averaging): {ensemble_acc*100:.2f}%")
print(f"   Improvement: {(ensemble_acc - avg_individual)*100:+.2f}%")

# ============================================================================
# FINAL SUMMARY
# ============================================================================

pipeline_elapsed = time.time() - pipeline_start

print("\n" + "="*80)
print("ğŸ TRAINING PIPELINE COMPLETED")
print("="*80)
print(f"\nâ±ï¸  Total training time: {pipeline_elapsed/60:.2f} minutes")
print(f"\nğŸ“Š Models trained: {len(model_predictions)} Random Forest models")
print(f"ğŸ“Š Training strategy: Ensemble with Probability Averaging")
print(f"ğŸ“Š Validation split: {VALIDATION_RATIO*100:.0f}%")

print("\n" + "="*80)
print("ğŸ”§ HYPERPARAMETERS")
print("="*80)
for key, value in RF_PARAMS.items():
    print(f"   {key}: {value}")

print("\n" + "="*80)
print("ğŸ“Š FINAL VALIDATION METRICS")
print("="*80)
print(f"   Accuracy:  {ensemble_acc*100:.2f}%")
print(f"   Precision: {ensemble_prec*100:.2f}%")
print(f"   Recall:    {ensemble_rec*100:.2f}%")
print(f"   F1-Score:  {ensemble_f1*100:.2f}%")

print("\n" + "="*80)
print("ğŸ“ NOTES")
print("="*80)
print("   âœ… Test data NOT used in training phase")
print("   âœ… Use evaluation step to run final test with test data")
print("   âœ… Probability saved for proper AUC calculation in evaluation")
print("   âœ… Image IDs used for accurate ensemble join")

print("\n" + "="*80)
print("ğŸš€ Next Step: Run evaluation script with test data")
print("="*80)

# Cleanup
df_train.unpersist()
df_val.unpersist()
df_ensemble.unpersist()
spark.catalog.clearCache()

spark.stop()
print("\nâœ… Spark session stopped. Training complete!")
