"""
Test Script - Verify Spark Setup
Kiá»ƒm tra xem Spark cÃ³ thá»ƒ Ä‘á»c data tá»« HDFS khÃ´ng
"""

from pyspark.sql import SparkSession

print("ğŸ§ª Testing Spark Setup...")

# Create Spark session
spark = SparkSession.builder \
    .appName("TestSetup") \
    .config("spark.eventLog.enabled", "true") \
    .config("spark.eventLog.dir", "hdfs://namenode:8020/spark-logs") \
    .getOrCreate()

print(f"âœ… Spark version: {spark.version}")
print(f"âœ… Master: {spark.sparkContext.master}")

# Test HDFS read
print("\nğŸ“‚ Testing HDFS read...")
try:
    # Read a small sample
    df = spark.read.format("binaryFile") \
        .load("hdfs://namenode:8020/user/data/raw/train/REAL/*.jpg") \
        .limit(10)
    
    count = df.count()
    print(f"âœ… Successfully read {count} files from HDFS")
    
    # Show schema
    print("\nğŸ“‹ Schema:")
    df.printSchema()
    
    # Show sample
    print("\nğŸ“Š Sample:")
    df.select("path", "length").show(5, truncate=False)
    
except Exception as e:
    print(f"âŒ Error reading from HDFS: {e}")

# Test write to HDFS
print("\nğŸ’¾ Testing HDFS write...")
try:
    test_data = [(1, "test"), (2, "data")]
    test_df = spark.createDataFrame(test_data, ["id", "value"])
    
    output_path = "hdfs://namenode:8020/user/data/test_output"
    test_df.write.mode("overwrite").parquet(output_path)
    
    print(f"âœ… Successfully wrote to {output_path}")
    
    # Read back
    read_back = spark.read.parquet(output_path)
    print(f"âœ… Successfully read back {read_back.count()} rows")
    read_back.show()
    
except Exception as e:
    print(f"âŒ Error writing to HDFS: {e}")

print("\nğŸ‰ Setup test completed!")
spark.stop()
